{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc97808",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Scope: Document assistant for Langchain website documentation\n",
    "\n",
    "Documentation sources:\n",
    "\n",
    "https://api.python.langchain.com/en/v0.1/langchain_api_reference.html\n",
    "\n",
    "https://python.langchain.com/docs/introduction/\n",
    "\n",
    "https://langchain-ai.github.io/langgraph/\n",
    "\n",
    "In order to download the web contents with all links, use the following command on cmd line for each source:\n",
    "wget -r -A.html -P langgraph-docs https://langchain-ai.github.io/langgraph/\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "110b7c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors.chain_filter import LLMChainFilter\n",
    "from langchain import hub\n",
    "from langchain.schema import Document\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from rank_bm25 import BM25Okapi\n",
    "from typing import List, Dict, Optional, Any\n",
    "from langchain.chains.combine_documents.stuff import create_stuff_documents_chain\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "from chromadb.config import Settings\n",
    "from langchain_community.document_transformers import LongContextReorder\n",
    "from langchain_core.runnables import Runnable\n",
    "from langchain_chroma import Chroma\n",
    "from pydantic import Field\n",
    "import msgspec\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words_en = set(stopwords.words('english'))\n",
    "stop_words_tr = set(stopwords.words('turkish'))\n",
    "\n",
    "import warnings\n",
    "from langsmith.utils import LangSmithMissingAPIKeyWarning\n",
    "warnings.filterwarnings(\"ignore\", category=LangSmithMissingAPIKeyWarning)\n",
    "\n",
    "class Data(msgspec.Struct):\n",
    "    documents: list[str]\n",
    "    metadata: list[dict]\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------\n",
    "#Custom BM25Retriever in order to utilize if all keywords are inside a text chunk, give higher score to that chunk in ranking with scores\n",
    "\n",
    "class CustomBM25Retriever(BaseRetriever):\n",
    "    k1: float = Field(default=1.2)\n",
    "    b: float = Field(default=0.75)\n",
    "    phrase_boost: float = Field(default=1.5)\n",
    "    k: int = Field(default=10)  # Number of top documents to retrieve\n",
    "    documents: List[Document] = Field(default_factory=list)\n",
    "    tokenized_docs: List[List[str]] = Field(default_factory=list)\n",
    "    bm25: Optional[BM25Okapi] = None\n",
    "\n",
    "    def __init__(self, documents: List[Document], k: int = 10, k1: float = 1.2, b: float = 0.75, phrase_boost: float = 1.5):\n",
    "        super().__init__()\n",
    "        self.documents = documents\n",
    "        self.k = k\n",
    "        self.k1 = k1\n",
    "        self.b = b\n",
    "        self.phrase_boost = phrase_boost\n",
    "        self.tokenized_docs = [self.tokenize(doc) for doc in self.documents]\n",
    "        self.bm25 = BM25Okapi(self.tokenized_docs, k1=self.k1, b=self.b)\n",
    "\n",
    "    @classmethod\n",
    "    def from_texts(cls, texts: List[str], metadatas: Optional[List[Dict]] = None, k: int = 10, bm25_params: Optional[Dict] = None):\n",
    "        \"\"\" Factory method to initialize from raw texts and metadata (similar to LangChain's BM25Retriever) \"\"\"\n",
    "        bm25_params = bm25_params or {\"k1\": 1.2, \"b\": 0.75, \"phrase_boost\": 1.0}\n",
    "        documents = [Document(page_content=text.lower(), metadata=meta or {}) for text, meta in zip(texts, metadatas or [{}] * len(texts))]\n",
    "        return cls(documents=documents, k=k, **bm25_params)\n",
    "\n",
    "\n",
    "    def tokenize(self, doc: Document):\n",
    "        \"\"\" Tokenizes both content and metadata for retrieval \"\"\"\n",
    "        metadata_str = \" \".join(f\"{key}: {value}\" for key, value in doc.metadata.items())\n",
    "        full_text = f\"{doc.page_content} {metadata_str}\"\n",
    "        return full_text.split()\n",
    "\n",
    "    def _get_relevant_documents(self, query: str, *, run_manager=None) -> List[Document]:\n",
    "        \"\"\" Retrieve and rank documents using BM25 with metadata and phrase boosting \"\"\"\n",
    "        if not self.bm25:\n",
    "            raise ValueError(\"BM25 model not initialized. Call __init__ first.\")\n",
    "\n",
    "        query = query.lower()\n",
    "        query = re.sub(r'[^\\w\\s.,%@()*-+/!&_?#|]', '', query) \n",
    "\n",
    "        tokens = word_tokenize(query)\n",
    "        filtered_query_tokens = [word for word in tokens if word not in stop_words_en]\n",
    "\n",
    "        scores = self.bm25.get_scores(filtered_query_tokens)\n",
    "\n",
    "        # Boost score if query appears as a phrase\n",
    "\n",
    "        boosted_scores = []\n",
    "        for i, doc in enumerate(self.documents):\n",
    "            full_text = f\"{doc.page_content} \" + \" \".join(f\"{key}: {value}\" for key, value in doc.metadata.items())\n",
    "            phrase_bonus = self.phrase_boost if query.lower() in full_text.lower() else 1.0           \n",
    "            boosted_scores.append(scores[i] * phrase_bonus)\n",
    "\n",
    "        # Rank documents by boosted BM25 score\n",
    "        ranked_docs = sorted(zip(self.documents, boosted_scores), key=lambda x: x[1], reverse=True)\n",
    "        return [doc[0] for doc in ranked_docs[:self.k]]  # Return only top_k documents\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "# Function to process retrieved documents\n",
    "class RetrieveAndReorder(Runnable):\n",
    "    def __init__(self, retriever):\n",
    "        self.retriever = retriever\n",
    "        self.reordering = LongContextReorder()\n",
    "\n",
    "    def invoke(self, input: Dict[str, Any], config=None, **kwargs) -> Dict[str, Any]:\n",
    "        question = input['question']\n",
    "        retrieved_docs: List[Document] = self.retriever.invoke(question)\n",
    "        if not retrieved_docs:\n",
    "            return {\"context\": [], \"question\": question}\n",
    "\n",
    "        reordered_docs = self.reordering.transform_documents(retrieved_docs)\n",
    "        return {\"context\": reordered_docs, \"question\": question}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff268c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic retriever from ChromaDB ready...\n",
      "bm25_data_docs_and_metadata.json read...\n",
      "BM25 retriever ready...\n",
      "length of data bm25: 430370\n",
      "Ensemble retriever and RetrieveAndReorder ready...\n",
      "Processing chain ready...\n",
      "Start querying...\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Chroma client (PersistentClient for persistent storage)\n",
    "from langchain import hub\n",
    "from langchain.chains.combine_documents.stuff import create_stuff_documents_chain\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "\n",
    "\n",
    "import warnings\n",
    "from langsmith.utils import LangSmithMissingAPIKeyWarning\n",
    "warnings.filterwarnings(\"ignore\", category=LangSmithMissingAPIKeyWarning)\n",
    "\n",
    "#----------------------------------------------------------\n",
    "\"\"\"\n",
    "Create the semantic retriever from the Chroma vectorstore\n",
    "\"\"\"\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"bge-m3\")\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name = \"my-doc-assistant-db\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"D:\\\\Langchain-Langgraph-Doc-WebSites\\\\__Databases\\\\langchain-docs-vectordb\"\n",
    "    )\n",
    "\n",
    "search_as = { \"k\": 5, \"lambda_mult\": 0.8,  \"score_threshold\": 0.1, \"fetch_k\": 10} \n",
    "semantic_retriever = vector_store.as_retriever(search_type=\"mmr\",search_kwargs=search_as)\n",
    "\n",
    "print(\"Semantic retriever from ChromaDB ready...\")\n",
    "\n",
    "#----------------------------------------------------------\n",
    "\"\"\"\n",
    "Create the BM25 Retriever\n",
    "\"\"\"\n",
    "\n",
    "#Read the document chunks and metadata as a file and put them into the BM25REtriever -- heavy RAM load\n",
    "folder = \"D:\\\\Langchain-Langgraph-Doc-WebSites\\\\__Databases\\\\langchain-docs-bm25-db\\\\\"\n",
    "with open(folder + 'bm25_data_docs_and_metadata.json', 'rb') as file:\n",
    "    data = msgspec.json.decode(file.read(), type=Data)\n",
    "\n",
    "print(\"bm25_data_docs_and_metadata.json read...\")\n",
    "\n",
    "# Initialize Custom BM25 Retriever instead of default BM25Retriever\n",
    "bm25_retriever = CustomBM25Retriever.from_texts(\n",
    "                                            data.documents, \n",
    "                                            data.metadata, \n",
    "                                            k=10, \n",
    "                                            bm25_params={\"k1\": 1.0, \"b\": 0.5, \"phrase_boost\": 1.5}\n",
    "                                            )\n",
    "\n",
    "print(\"BM25 retriever ready...\")\n",
    "print(f\"length of data bm25: {len(data.documents)}\")\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "\"\"\"\n",
    "Create the ensemble retriever with BM25 retriever and semantic retriever. \n",
    "Then, reorder the input documents against position bias for llm.\n",
    "\"\"\"\n",
    "#Create the ensemble retriever\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, semantic_retriever], \n",
    "    weights=[0.5, 0.5]\n",
    ")\n",
    "\n",
    "# Create the retrieval and reordering runnable\n",
    "retrieve_and_reorder = RetrieveAndReorder(ensemble_retriever)\n",
    "\n",
    "print(\"Ensemble retriever and RetrieveAndReorder ready...\")\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "\"\"\"\n",
    "Create the retrieval chain to produce outputs.\n",
    "\"\"\"\n",
    "retrieval_qa_chat_prompt = hub.pull(\"langchain-ai/retrieval-qa-chat\")\n",
    "\n",
    "llm = ChatOllama(model=\"cogito:14b\", temperature=0.1, repeat_penalty=1.1, disable_streaming=False)\n",
    "\n",
    "# Create the LLM-based filter\n",
    "llm_filter = LLMChainFilter.from_llm(llm)\n",
    "\n",
    "# Create the contextual compression retriever\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=llm_filter,\n",
    "    base_retriever=semantic_retriever #ensemble_retriever #bm25_retriever #semantic_retriever\n",
    ")\n",
    "\n",
    "\n",
    "combine_docs_chain = create_stuff_documents_chain(\n",
    "    llm=llm, \n",
    "    prompt=retrieval_qa_chat_prompt\n",
    ")\n",
    "\n",
    "\n",
    "retrieval_chain = create_retrieval_chain(\n",
    "    retriever = compression_retriever, #bm25_retriever, #compression_retriever #semantic_retriever\n",
    "    combine_docs_chain = combine_docs_chain,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print(\"Processing chain ready...\")\n",
    "print(\"Start querying...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457359fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: \n",
      "LangChain is an open source orchestration framework for building applications using large language models (LLMs) like chatbots and virtual agents. It was launched by Harrison Chase in October 2022 and has gained popularity as the fastest-growing open source project on Github in June 2023.\n",
      "\n",
      "Sources: \n",
      "0 - D:\\Langchain-Langgraph-Doc-WebSites\\langchain-langgraph-docs\\langchain-docs\\python.langchain.com\\v0.1\\docs\\modules\\agents\\agent_types\\react\\index.html\n",
      "1 - D:\\Langchain-Langgraph-Doc-WebSites\\langchain-langgraph-docs\\langchain-docs\\python.langchain.com\\v0.1\\docs\\modules\\agents\\agent_types\\json_agent\\index.html\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n!!!\\n\\nThink and read about a fast and effective rag pipeline.\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Query to search in a RAG with streaming.\n",
    "\"\"\"\n",
    "\n",
    "import warnings\n",
    "from langsmith.utils import LangSmithMissingAPIKeyWarning\n",
    "warnings.filterwarnings(\"ignore\", category=LangSmithMissingAPIKeyWarning)\n",
    "\n",
    "\n",
    "query = \"what is the definition of langchain?\"\n",
    "\n",
    "#Create a list of sources from metadata and show each source once, do not repeat\n",
    "sources = []\n",
    "seen_sources = set()\n",
    "print(\"Response: \")\n",
    "for chunk in retrieval_chain.stream({\"input\": query}):\n",
    "    for key, value in chunk.items():     \n",
    "        #Streaming part is under the key='answer'  \n",
    "        if key == 'answer':\n",
    "            print(chunk['answer'], end=\"\", flush=True)\n",
    "        #Metadata and full answer is under the key='context'\n",
    "        #Do not add dublicated sources\n",
    "        if key == 'context':\n",
    "           all_sources = [doc.metadata[\"source\"] for doc in chunk['context']]\n",
    "           for source in all_sources:\n",
    "                if source not in seen_sources:\n",
    "                    seen_sources.add(source)            \n",
    "                    sources.append(source)\n",
    "\n",
    "print(\"\\n\\nSources: \")\n",
    "for i, chunk in zip(range(len(sources)), sources):\n",
    "    print(f\"{i} - {chunk}\\n\", end=\"\", flush=True)  \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "!!!\n",
    "\n",
    "Think and read about a fast and effective rag pipeline.\n",
    "Think about finding a phrase or keyword in a document. so, show the documents\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e694696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: \n",
      "Based on the provided context, LangChain can be defined as:\n",
      "\n",
      "An open source orchestration framework for building applications using large language models (LLMs). It provides a library of abstractions in Python and JavaScript that help developers create various AI-powered applications like chatbots and virtual agents. Launched by Harrison Chase in October 2022, it gained significant popularity as the fastest-growing open source project on GitHub by June 2023.\n",
      "\n",
      "The framework simplifies integration with external data sources and software workflows, supporting multiple LLM providers including OpenAI, Google, and IBM. It includes tools for language models to interact with the world through interfaces that can be invoked effectively using serializable inputs (strings and Python dict objects).\n",
      "Sources: \n",
      "0 - D:\\Langchain-Langgraph-Doc-WebSites\\langchain-langgraph-docs\\langchain-docs\\python.langchain.com\\v0.1\\docs\\modules\\agents\\agent_types\\openai_tools\\index.html\n",
      "1 - D:\\Langchain-Langgraph-Doc-WebSites\\langchain-langgraph-docs\\langchain-docs\\python.langchain.com\\v0.1\\docs\\modules\\agents\\agent_types\\react\\index.html\n",
      "2 - D:\\Langchain-Langgraph-Doc-WebSites\\langchain-langgraph-docs\\langchain-docs\\python.langchain.com\\v0.1\\docs\\modules\\agents\\agent_types\\json_agent\\index.html\n",
      "3 - D:\\Langchain-Langgraph-Doc-WebSites\\langchain-langgraph-docs\\langchain-docs\\python.langchain.com\\v0.2\\docs\\how_to\\convert_runnable_to_tool\\index.html\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Query to search in a RAG without streaming.\n",
    "\"\"\"\n",
    "\n",
    "import warnings\n",
    "from langsmith.utils import LangSmithMissingAPIKeyWarning\n",
    "warnings.filterwarnings(\"ignore\", category=LangSmithMissingAPIKeyWarning)\n",
    "\n",
    "\n",
    "query = \"what is the definition of langchain?\"\n",
    "\n",
    "response = retrieval_chain.invoke(input={\"input\": query})\n",
    "\n",
    "\n",
    "print(\"Response: \")\n",
    "for chunk in response[\"answer\"]:\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "\n",
    "print(\"\\nSources: \")\n",
    "all_sources = [doc.metadata[\"source\"] for doc in response[\"context\"]]\n",
    "\n",
    "sources = []\n",
    "seen_sources = set()\n",
    "for source in all_sources:\n",
    "    if source not in seen_sources:\n",
    "        seen_sources.add(source)            \n",
    "        sources.append(source)\n",
    "\n",
    "for i, chunk in zip(range(len(sources)), sources):\n",
    "    print(f\"{i} - {chunk}\\n\", end=\"\", flush=True)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
