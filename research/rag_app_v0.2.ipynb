{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc97808",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Scope: Document assistant for Langchain website documentation\n",
    "\n",
    "Documentation sources:\n",
    "\n",
    "https://api.python.langchain.com/en/v0.1/langchain_api_reference.html\n",
    "\n",
    "https://python.langchain.com/docs/introduction/\n",
    "\n",
    "https://langchain-ai.github.io/langgraph/\n",
    "\n",
    "In order to download the web contents with all links, use the following command on cmd line for each source:\n",
    "wget -r -A.html -P langgraph-docs https://langchain-ai.github.io/langgraph/\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "110b7c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain import hub\n",
    "from langchain.schema import Document\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from rank_bm25 import BM25Okapi\n",
    "from typing import List, Dict, Optional, Any\n",
    "from langchain.chains.combine_documents.stuff import create_stuff_documents_chain\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "from chromadb.config import Settings\n",
    "from langchain_community.document_transformers import LongContextReorder\n",
    "from langchain_core.runnables import Runnable\n",
    "from langchain_chroma import Chroma\n",
    "from pydantic import Field\n",
    "import msgspec\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words_en = set(stopwords.words('english'))\n",
    "stop_words_tr = set(stopwords.words('turkish'))\n",
    "\n",
    "import warnings\n",
    "from langsmith.utils import LangSmithMissingAPIKeyWarning\n",
    "warnings.filterwarnings(\"ignore\", category=LangSmithMissingAPIKeyWarning)\n",
    "\n",
    "class Data(msgspec.Struct):\n",
    "    documents: list[str]\n",
    "    metadata: list[dict]\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------\n",
    "#Custom BM25Retriever in order to utilize if all keywords are inside a text chunk, give higher score to that chunk in ranking with scores\n",
    "\n",
    "class CustomBM25Retriever(BaseRetriever):\n",
    "    k1: float = Field(default=1.2)\n",
    "    b: float = Field(default=0.75)\n",
    "    phrase_boost: float = Field(default=1.5)\n",
    "    k: int = Field(default=10)  # Number of top documents to retrieve\n",
    "    documents: List[Document] = Field(default_factory=list)\n",
    "    tokenized_docs: List[List[str]] = Field(default_factory=list)\n",
    "    bm25: Optional[BM25Okapi] = None\n",
    "\n",
    "    def __init__(self, documents: List[Document], k: int = 10, k1: float = 1.2, b: float = 0.75, phrase_boost: float = 1.5):\n",
    "        super().__init__()\n",
    "        self.documents = documents\n",
    "        self.k = k\n",
    "        self.k1 = k1\n",
    "        self.b = b\n",
    "        self.phrase_boost = phrase_boost\n",
    "        self.tokenized_docs = [self.tokenize(doc) for doc in self.documents]\n",
    "        self.bm25 = BM25Okapi(self.tokenized_docs, k1=self.k1, b=self.b)\n",
    "\n",
    "    @classmethod\n",
    "    def from_texts(cls, texts: List[str], metadatas: Optional[List[Dict]] = None, k: int = 10, bm25_params: Optional[Dict] = None):\n",
    "        \"\"\" Factory method to initialize from raw texts and metadata (similar to LangChain's BM25Retriever) \"\"\"\n",
    "        bm25_params = bm25_params or {\"k1\": 1.2, \"b\": 0.75, \"phrase_boost\": 1.0}\n",
    "        documents = [Document(page_content=text.lower(), metadata=meta or {}) for text, meta in zip(texts, metadatas or [{}] * len(texts))]\n",
    "        return cls(documents=documents, k=k, **bm25_params)\n",
    "\n",
    "\n",
    "    def tokenize(self, doc: Document):\n",
    "        \"\"\" Tokenizes both content and metadata for retrieval \"\"\"\n",
    "        metadata_str = \" \".join(f\"{key}: {value}\" for key, value in doc.metadata.items())\n",
    "        full_text = f\"{doc.page_content} {metadata_str}\"\n",
    "        return full_text.split()\n",
    "\n",
    "    def _get_relevant_documents(self, query: str, *, run_manager=None) -> List[Document]:\n",
    "        \"\"\" Retrieve and rank documents using BM25 with metadata and phrase boosting \"\"\"\n",
    "        if not self.bm25:\n",
    "            raise ValueError(\"BM25 model not initialized. Call __init__ first.\")\n",
    "\n",
    "        query = query.lower()\n",
    "        query = re.sub(r'[^\\w\\s.,%@()*-+/!&_?#|]', '', query) \n",
    "\n",
    "        tokens = word_tokenize(query)\n",
    "        filtered_query_tokens = [word for word in tokens if word not in stop_words_en]\n",
    "\n",
    "        scores = self.bm25.get_scores(filtered_query_tokens)\n",
    "\n",
    "        # Boost score if query appears as a phrase\n",
    "\n",
    "        boosted_scores = []\n",
    "        for i, doc in enumerate(self.documents):\n",
    "            full_text = f\"{doc.page_content} \" + \" \".join(f\"{key}: {value}\" for key, value in doc.metadata.items())\n",
    "            phrase_bonus = self.phrase_boost if query.lower() in full_text.lower() else 1.0           \n",
    "            boosted_scores.append(scores[i] * phrase_bonus)\n",
    "\n",
    "        # Rank documents by boosted BM25 score\n",
    "        ranked_docs = sorted(zip(self.documents, boosted_scores), key=lambda x: x[1], reverse=True)\n",
    "        return [doc[0] for doc in ranked_docs[:self.k]]  # Return only top_k documents\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "# Function to process retrieved documents\n",
    "class RetrieveAndReorder(Runnable):\n",
    "    def __init__(self, retriever):\n",
    "        self.retriever = retriever\n",
    "        self.reordering = LongContextReorder()\n",
    "\n",
    "    def invoke(self, input: Dict[str, Any], config=None, **kwargs) -> Dict[str, Any]:\n",
    "        question = input['question']\n",
    "        retrieved_docs: List[Document] = self.retriever.invoke(question)\n",
    "        if not retrieved_docs:\n",
    "            return {\"context\": [], \"question\": question}\n",
    "\n",
    "        reordered_docs = self.reordering.transform_documents(retrieved_docs)\n",
    "        return {\"context\": reordered_docs, \"question\": question}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff268c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic retriever from ChromaDB ready...\n",
      "bm25_data_docs_and_metadata.json read...\n",
      "BM25 retriever ready...\n",
      "length of data bm25: 430370\n",
      "Ensemble retriever and RetrieveAndReorder ready...\n",
      "Processing chain ready...\n",
      "Start querying...\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Chroma client (PersistentClient for persistent storage)\n",
    "from langchain import hub\n",
    "from langchain.chains.combine_documents.stuff import create_stuff_documents_chain\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "\n",
    "\n",
    "import warnings\n",
    "from langsmith.utils import LangSmithMissingAPIKeyWarning\n",
    "warnings.filterwarnings(\"ignore\", category=LangSmithMissingAPIKeyWarning)\n",
    "\n",
    "#----------------------------------------------------------\n",
    "\"\"\"\n",
    "Create the semantic retriever from the Chroma vectorstore\n",
    "\"\"\"\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"bge-m3\")\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name = \"my-doc-assistant-db\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"D:\\\\Langchain-Langgraph-Doc-WebSites\\\\__Databases\\\\langchain-docs-vectordb\"\n",
    "    )\n",
    "\n",
    "search_as = { \"k\": 5, \"lambda_mult\": 0.8,  \"score_threshold\": 0.1, \"fetch_k\": 10} \n",
    "semantic_retriever = vector_store.as_retriever(search_type=\"mmr\",search_kwargs=search_as)\n",
    "\n",
    "print(\"Semantic retriever from ChromaDB ready...\")\n",
    "\n",
    "#----------------------------------------------------------\n",
    "\"\"\"\n",
    "Create the BM25 Retriever\n",
    "\"\"\"\n",
    "\n",
    "#Read the document chunks and metadata as a file and put them into the BM25REtriever -- heavy RAM load\n",
    "folder = \"D:\\\\Langchain-Langgraph-Doc-WebSites\\\\__Databases\\\\langchain-docs-bm25-db\\\\\"\n",
    "with open(folder + 'bm25_data_docs_and_metadata.json', 'rb') as file:\n",
    "    data = msgspec.json.decode(file.read(), type=Data)\n",
    "\n",
    "print(\"bm25_data_docs_and_metadata.json read...\")\n",
    "\n",
    "# Initialize Custom BM25 Retriever instead of default BM25Retriever\n",
    "bm25_retriever = CustomBM25Retriever.from_texts(\n",
    "                                            data.documents, \n",
    "                                            data.metadata, \n",
    "                                            k=10, \n",
    "                                            bm25_params={\"k1\": 1.0, \"b\": 0.5, \"phrase_boost\": 1.5}\n",
    "                                            )\n",
    "\n",
    "print(\"BM25 retriever ready...\")\n",
    "print(f\"length of data bm25: {len(data.documents)}\")\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "\"\"\"\n",
    "Create the ensemble retriever with BM25 retriever and semantic retriever. \n",
    "Then, reorder the input documents against position bias for llm.\n",
    "\"\"\"\n",
    "#Create the ensemble retriever\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, semantic_retriever], \n",
    "    weights=[0.5, 0.5]\n",
    ")\n",
    "\n",
    "# Create the retrieval and reordering runnable\n",
    "retrieve_and_reorder = RetrieveAndReorder(ensemble_retriever)\n",
    "\n",
    "print(\"Ensemble retriever and RetrieveAndReorder ready...\")\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "\"\"\"\n",
    "Create the retrieval chain to produce outputs.\n",
    "\"\"\"\n",
    "retrieval_qa_chat_prompt = hub.pull(\"langchain-ai/retrieval-qa-chat\")\n",
    "\n",
    "llm = ChatOllama(model=\"cogito:14b\", temperature=0.1, repeat_penalty=1.1, disable_streaming=False)\n",
    "\n",
    "combine_docs_chain = create_stuff_documents_chain(\n",
    "    llm=llm, \n",
    "    prompt=retrieval_qa_chat_prompt\n",
    ")\n",
    "\n",
    "\n",
    "retrieval_chain = create_retrieval_chain(\n",
    "    retriever = ensemble_retriever,\n",
    "    combine_docs_chain = combine_docs_chain,\n",
    ")\n",
    "\n",
    "print(\"Processing chain ready...\")\n",
    "print(\"Start querying...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "457359fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: \n",
      "I cannot determine what \"angara bebesi\" refers to based on the provided context. The context appears to contain code snippets and type definitions related to a programming framework, but does not mention anything about \"angara bebesi.\" Without additional information or context, I cannot provide an answer about this term.\n",
      "\n",
      "Sources: \n",
      "0 - D:\\Langchain-Langgraph-Doc-WebSites\\langchain-langgraph-docs\\langgraph-docs\\langchain-ai.github.io\\langgraphjs\\reference\\classes\\langgraph.CompiledGraph.html\n",
      "1 - D:\\Langchain-Langgraph-Doc-WebSites\\langchain-langgraph-docs\\langchain-docs\\python.langchain.com\\docs\\integrations\\tools\\nvidia_riva\\index.html\n",
      "2 - D:\\Langchain-Langgraph-Doc-WebSites\\langchain-langgraph-docs\\langgraph-docs\\langchain-ai.github.io\\langgraphjs\\reference\\classes\\langgraph_prebuilt.ToolExecutor.html\n",
      "3 - D:\\Langchain-Langgraph-Doc-WebSites\\langchain-langgraph-docs\\langgraph-docs\\langchain-ai.github.io\\langgraphjs\\reference\\classes\\langgraph_prebuilt.ToolNode.html\n",
      "4 - D:\\Langchain-Langgraph-Doc-WebSites\\langchain-langgraph-docs\\langgraph-docs\\langchain-ai.github.io\\langgraphjs\\reference\\classes\\langgraph.CompiledStateGraph.html\n",
      "5 - D:\\Langchain-Langgraph-Doc-WebSites\\langchain-langgraph-docs\\langchain-docs\\python.langchain.com\\docs\\integrations\\tools\\nvidia_riva\\index.html\n",
      "6 - D:\\Langchain-Langgraph-Doc-WebSites\\langchain-langgraph-docs\\langgraph-docs\\langchain-ai.github.io\\langgraphjs\\reference\\classes\\langgraph.StateGraph.html\n",
      "7 - D:\\Langchain-Langgraph-Doc-WebSites\\langchain-langgraph-docs\\langchain-docs\\python.langchain.com\\docs\\integrations\\tools\\nvidia_riva\\index.html\n",
      "8 - D:\\Langchain-Langgraph-Doc-WebSites\\langchain-langgraph-docs\\langgraph-docs\\langchain-ai.github.io\\langgraphjs\\reference\\classes\\langgraph.StateGraph.html\n",
      "9 - D:\\Langchain-Langgraph-Doc-WebSites\\langchain-langgraph-docs\\langchain-docs\\python.langchain.com\\v0.2\\docs\\integrations\\tools\\nvidia_riva\\index.html\n",
      "10 - D:\\Langchain-Langgraph-Doc-WebSites\\langchain-langgraph-docs\\langgraph-docs\\langchain-ai.github.io\\langgraphjs\\reference\\classes\\langgraph.StateGraph.html\n",
      "11 - D:\\Langchain-Langgraph-Doc-WebSites\\langchain-langgraph-docs\\langgraph-docs\\langchain-ai.github.io\\langgraphjs\\reference\\classes\\langgraph.PregelNode.html\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Query to search in a RAG with streaming.\n",
    "\"\"\"\n",
    "\n",
    "import warnings\n",
    "from langsmith.utils import LangSmithMissingAPIKeyWarning\n",
    "warnings.filterwarnings(\"ignore\", category=LangSmithMissingAPIKeyWarning)\n",
    "\n",
    "\n",
    "query = \"what is angara bebesi?\"\n",
    "\n",
    "sources = []\n",
    "\n",
    "print(\"Response: \")\n",
    "for chunk in retrieval_chain.stream({\"input\": query}):\n",
    "    for key, value in chunk.items():       \n",
    "        if key == 'answer':\n",
    "            print(chunk['answer'], end=\"\", flush=True)\n",
    "        if key == 'context':\n",
    "            sources.extend([doc.metadata[\"source\"] for doc in chunk['context']])\n",
    "\n",
    "\n",
    "print(\"\\n\\nSources: \")\n",
    "for i, chunk in zip(range(len(sources)), sources):\n",
    "    print(f\"{i} - {chunk}\\n\", end=\"\", flush=True)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c413861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: \n",
      "LangGraph is a library within the LangChain ecosystem that helps developers build stateful multi-agent applications using language models. It provides tools for coordinating multiple AI agents or chains in a structured way, allowing developers to focus on high-level application logic rather than managing complex agent interactions.\n",
      "\n",
      "Key features of LangGraph include:\n",
      "- Managing data flow and operation sequences\n",
      "- Creating workflows and state machines\n",
      "- Coordinating multiple LLM agents\n",
      "- Building more complex applications beyond simple query-response systems\n",
      "\n",
      "LangGraph is particularly useful for developing sophisticated AI applications that require coordination between different language model components.\n",
      "Sources: \n",
      "0 - D:\\Langchain-Langgraph-Doc-WebSites\\langchain-langgraph-docs\\langgraph-docs\\langchain-ai.github.io\\langgraph\\tutorials\\langgraph-platform\\local-server\\index.html\n",
      "1 - D:\\Langchain-Langgraph-Doc-WebSites\\langchain-langgraph-docs\\langgraph-docs\\langchain-ai.github.io\\langgraph\\cloud\\quick_start\\index.html\n",
      "2 - D:\\Langchain-Langgraph-Doc-WebSites\\langchain-langgraph-docs\\langgraph-docs\\langchain-ai.github.io\\langgraph\\tutorials\\introduction\\index.html\n",
      "3 - D:\\Langchain-Langgraph-Doc-WebSites\\langchain-langgraph-docs\\langgraph-docs\\langchain-ai.github.io\\langgraph\\tutorials\\introduction\\index.html\n",
      "4 - D:\\Langchain-Langgraph-Doc-WebSites\\langchain-langgraph-docs\\langgraph-docs\\langchain-ai.github.io\\langgraphjs\\how-tos\\define-state\\index.html\n",
      "5 - D:\\Langchain-Langgraph-Doc-WebSites\\langchain-langgraph-docs\\langchain-docs\\python.langchain.com\\v0.2\\docs\\concepts\\index.html\n",
      "6 - D:\\Langchain-Langgraph-Doc-WebSites\\langchain-langgraph-docs\\langgraph-docs\\langchain-ai.github.io\\langgraphjs\\reference\\classes\\checkpoint_mongodb.MongoDBSaver.html\n",
      "7 - D:\\Langchain-Langgraph-Doc-WebSites\\langchain-langgraph-docs\\langchain-docs\\python.langchain.com\\v0.1\\docs\\use_cases\\query_analysis\\techniques\\step_back\\index.html\n",
      "8 - D:\\Langchain-Langgraph-Doc-WebSites\\langchain-langgraph-docs\\langgraph-docs\\langchain-ai.github.io\\langgraph\\tutorials\\introduction\\index.html\n",
      "9 - D:\\Langchain-Langgraph-Doc-WebSites\\langchain-langgraph-docs\\langgraph-docs\\langchain-ai.github.io\\langgraphjs\\how-tos\\command\\index.html\n",
      "10 - D:\\Langchain-Langgraph-Doc-WebSites\\langchain-langgraph-docs\\langgraph-docs\\langchain-ai.github.io\\langgraphjs\\troubleshooting\\errors\\UNREACHABLE_NODE\\index.html\n",
      "11 - D:\\Langchain-Langgraph-Doc-WebSites\\langchain-langgraph-docs\\langgraph-docs\\langchain-ai.github.io\\langgraphjs\\reference\\classes\\langgraph_prebuilt.ToolExecutor.html\n",
      "12 - D:\\Langchain-Langgraph-Doc-WebSites\\langchain-langgraph-docs\\langgraph-docs\\langchain-ai.github.io\\langgraphjs\\reference\\classes\\langgraph_prebuilt.ToolNode.html\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Query to search in a RAG without streaming.\n",
    "\"\"\"\n",
    "\n",
    "import warnings\n",
    "from langsmith.utils import LangSmithMissingAPIKeyWarning\n",
    "warnings.filterwarnings(\"ignore\", category=LangSmithMissingAPIKeyWarning)\n",
    "\n",
    "\n",
    "query = \"what is langgraph?\"\n",
    "\n",
    "response = retrieval_chain.invoke(input={\"input\": query})\n",
    "\n",
    "\n",
    "print(\"Response: \")\n",
    "for chunk in response[\"answer\"]:\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "\n",
    "print(\"\\nSources: \")\n",
    "sources = [doc.metadata[\"source\"] for doc in response[\"context\"]]\n",
    "for i, chunk in zip(range(len(sources)), sources):\n",
    "    print(f\"{i} - {chunk}\\n\", end=\"\", flush=True)  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
