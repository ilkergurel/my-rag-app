{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from langchain_community.document_loaders import PyPDFLoader, UnstructuredEPubLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from chromadb.utils.embedding_functions import OllamaEmbeddingFunction\n",
    "from collections import defaultdict\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from chromadb import HttpClient\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import fitz\n",
    "\n",
    "# Recursively find all .pdf files in subdirectories\n",
    "\n",
    "def get_docs(directory):\n",
    "    file_dict = defaultdict(list)\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.lower().endswith('.pdf') or  file.lower().endswith('.epub'):  # Check if it's a .pdf or .epub file         \n",
    "                file_path =  os.path.join(root, file)                    #Obtain filepath and remove path length control with \\\\?\\\\\n",
    "                file_name, file_ext = os.path.splitext(file)                         #Obtain filename without extension                                   \n",
    "                parent_path = os.path.basename(os.path.dirname(file_path))           #Obtain parent directory\n",
    "                file_size = os.path.getsize(file_path)                               #Obtain file size\n",
    "                file_dict[file_name].append([file_path, parent_path, file_size, file_ext])\n",
    "\n",
    "\n",
    "    return file_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of element in chromadb: 3076636\n",
      "Number of database elements: 3076636\n",
      "Number of documents  in harddisk: 1963\n",
      "Number of documents in database: 1863\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "\n",
    "# Initialize the Chroma client (PersistentClient for persistent storage)\n",
    "client = chromadb.PersistentClient(path=\"D:\\Bilgi\\__Databases\\Bilgi_my_chroma_db_with_langchain\")\n",
    "\n",
    "# Access your collection by name\n",
    "collection = client.get_collection(\"my-rag-db\")\n",
    "\n",
    "total_items = collection.count()\n",
    "print(f\"Total number of element in chromadb: {total_items}\")\n",
    "\n",
    "batch_size = 100000\n",
    "\n",
    "list_items_info = []\n",
    "counter = 0\n",
    "documents = defaultdict(list)\n",
    "\n",
    "for offset in range(0, total_items, batch_size):\n",
    "    # Retrieve a batch of data\n",
    "\n",
    "    print(f\"Counter: {counter} / {total_items}  \", end=\"\\r\")\n",
    "\n",
    "    batch = collection.get(\n",
    "        include=[\"documents\", \"metadatas\"],\n",
    "        limit=batch_size,\n",
    "        offset=offset\n",
    "    )\n",
    "\n",
    "    # Process each item in the batch\n",
    "    for doc, meta, id in zip(batch[\"documents\"], batch[\"metadatas\"], batch[\"ids\"]):\n",
    "        # Replace the following line with your processing logic\n",
    "        #print(f\"Document: {doc}\\nMetadata: {meta}\\nIds: {id}\\n\")\n",
    "\n",
    "        path = meta.get(\"source\", \"Unknown\")\n",
    "        doc_name = path.split(\"\\\\\")[-1]\n",
    "        page = meta.get(\"page\", \"Unknown\")\n",
    "        total_pages = meta.get(\"total_pages\", \"Unknown\")\n",
    "        chunk_length = len(doc)\n",
    "\n",
    "        list_items_info.append([id, chunk_length, path, doc_name, page, total_pages, doc])\n",
    "\n",
    "        #Get the documents which are in the database\n",
    "        if not path in documents:\n",
    "            documents[path].append([chunk_length, total_pages])\n",
    "\n",
    "\n",
    "        counter += 1\n",
    "    \n",
    "\n",
    "print(f\"Number of database elements: {len(list_items_info)}\")\n",
    "\n",
    "directory = \"D:\\\\Bilgi\"\n",
    "file_dict = get_docs(directory)\n",
    "\n",
    "print(f\"Number of documents  in harddisk: {len(file_dict)}\")\n",
    "\n",
    "print(f\"Number of documents in database: {len(documents)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing docs: 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\AudioProcessing\\\\(ebook) Prentice Hall - Digital Processing Of Speech Signals (Lawrence R. Rabiner & Ronald W. Schafer) (scanned).pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\AudioProcessing\\\\[eBook ENG] [DSP-audio] - Digital Audio Signal Processing - Zolzer.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Big Data\\\\Data Mining Process with Neural Networks - Joseph P Bigus.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Biography\\\\Mao Tse-Tung - A Biography By Ross Terrill.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Business\\\\Amos Tversky And Daniel Kahneman - Prospect Theory - An Analysis Of Decision Under Risk (1979).pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Business\\\\MIT_Managing_the_Total_Customer_Experience.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Circuits\\\\(ebook - electronics) - Practical RF Circuit Design for Modern Wireless Systems - Vol. 1- Passive Circuits & Systems (Besser Gilmore 2003).pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Circuits\\\\Allen, Holberg - CMOS Analog Circuit Design second edition.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Circuits\\\\Analog Circuit Design - Sansen & Huijsing.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Circuits\\\\Analog Circuit Design - Volt Electronics - Mixed-Mode Systems - Low-Noise and RF Power Amplifiers for Telecommunication.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Circuits\\\\Analog Integrated Circuit Design - Johns & Martin.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Circuits\\\\Handbook of Analog Circuit Design - D. Feucht (AP) WW.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Circuits\\\\Prentice Hall - Phase-Locked Loop Circuit Design.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Circuits\\\\Secrets of Rf Circuit Design (McGraw-Hill Joseph J. Carr).pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Deep Learning\\\\Artificial Intelligence - IEEE Artificial Neural Networks A Tutorial.PDF',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Deep Learning\\\\Learning from data - A short course - Abu-Mostafa.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Deep Learning\\\\Natural Language Processing\\\\2009-natural_language_processing_with_python.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Deep Learning\\\\Natural Language Processing\\\\Speech and Language Processing - An Introduction to Natural Language Processing, Computational Linguistics and Speech Recognition.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Deep Learning\\\\Natural Language Processing\\\\W. Chou - Pattern Recognition in Speech and Language Processing.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Design & Manufacturing\\\\3642231861 Human-Computer Systems Interaction. Backgrounds and Applications 2. Part 1 (Springer, AISC 98, 2012).pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Design & Manufacturing\\\\Springer - Human-Computer Interaction - Users And Applications, 14 Conf , Hci 2011, Part Iv (2011) [9783642216183].pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\DevOps\\\\The Phoenix Project_ A Novel About IT, DevOps, and Helping Your Business Win - Kim, Gene.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Economy\\\\(Ebook) Technical Analysis of the Financial Markets - Comprehensive Guide to Trading Methods & Application by John J. Murphy (1999).pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Influencing & Communication & Relationships\\\\Business - McGraw Hill - Customer Relationship Management - CRM.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Influencing & Communication & Relationships\\\\Negotiation - Tony Robbins - The Power To Influence (Sales Mastery) - Backtrack Notes (175P).pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Influencing & Communication & Relationships\\\\Nlp - Kevin Hogan - The Psychology Of Persuasion How To Persuade Others To Your Way Of Thinking.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Influencing & Communication & Relationships\\\\The Psychology Of Persuasion How To Persuade Others To Your Way Of Thinking - Kevin Hogan.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Investing\\\\Benjamin Graham & David Dodd - Security analysis.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Investing\\\\Buffett, Warren. Fundamentals of Managerial Economics.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Investing\\\\Finance.Modern Portfolio Theory and Investment Analysis-6th ed.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Investing\\\\Fooled By Randomness - Taleb, Nassim (2007).pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Investing\\\\Invest - How to Make Money Trading Stocks and Commodities - Sranko, George.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Investing\\\\__The Little Book Of Common Sense Investing (BOGLE John 2007 W.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Leadership & Organization\\\\Harvard Business Review - Leadership And Strategy For The Twenty-First Century - 022008.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Leadership & Organization\\\\How It Works Book of Great Inventors & Their Creations 2015 Edition - Imagine Publishing (Imagine Publishing;How It Works Bookazine;2015;9781785460203;eng).pdf',\n",
       " \"E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Leadership & Organization\\\\John C Maxwell - There's No Such Thing As Business Ethics.pdf\",\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Leadership & Organization\\\\Leadership & Strategy - Harvard Business Review.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Leadership & Organization\\\\psychology - NLP - Robert Dilts - Visionary Leadership Skills.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Leadership & Organization\\\\PSYCHOLOGY - NLP.-.Robert.Dilts.-.Visionary.Leadership.Skills.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Leadership & Organization\\\\Schelling - The Strategy Of Conflict.pdf',\n",
       " \"E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Leadership & Organization\\\\The Leader's Guide To Lateral Thinking Skills - Unlocking The Creativity And Innovation In You And Your Team.pdf\",\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Marketing\\\\Longman - Market Leader - Advanced Business English Course Book.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Martial Arts\\\\Donn F Draeger - The Martial Arts And Ways Of Japan Volume One - Classical Budo..pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Martial Arts\\\\Donn F Draeger - The Martial Arts And Ways Of Japan Volume Two - Classical Budo.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Martial Arts\\\\Randy Gonzalez - Social Survival Tactics. A guide to basic self-defense and personal safety strategy.pdf',\n",
       " \"E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Politics\\\\(Ebook - Pdf) Sun Tzu's Art Of War.pdf\",\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Politics\\\\History of the Second World War ( Basil Liddell Hart, 1970).pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Politics\\\\Leo Strauss - Machiavelli Prince.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Politics\\\\Skinner - Machiavelli A Very Short Introduction.pdf',\n",
       " \"E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Politics\\\\Strategy And Tactics No 075 - Napoleon's Art Of War - Eylau And Dresden [Jul-Aug 79].pdf\",\n",
       " \"E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Politics\\\\Strauss, Leo -Machiavelli's Intention The Prince.pdf\",\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Science\\\\The Character Of Physical Law (Mit Press) - R P Feynman(Mr)(Acro9).pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Self Improvement\\\\( EBOOK - PDF - ENG) Covey, Stephen - The Seven Habits Of Highly Effective People.pdf',\n",
       " \"E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Self Improvement\\\\(ebook) Reinventing Yourself. How To Become The Person You've Always Wanted To Be by Steve Chandler.pdf\",\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Self Improvement\\\\Napoleon Hill - Keys To Success The 17 Principles Of Personal Achievement (1994).pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Self Improvement\\\\Napoleon Hill - Think And Grow Rich.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Self Improvement\\\\Taleb, Nassim Nicholas - Fooled By Randomness; The Hidden Role Of Chance In Markets And Life _.pdf',\n",
       " \"E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Self Improvement\\\\•••Napoleon Hill   Napoleon Hill's Keys to Success  The 17 Principles of Personal Achievement (1997, Plume)             JM20352 Col .pdf\",\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Signal Processing\\\\(Control - DSP) - Digital Signal Processing 3ed Proakis, Manolakis -.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Signal Processing\\\\Calculus.A.Complete.Course,.Robert.A..Adams,.Christopher.Essex,.7ed,.Pearson,.2010.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Signal Processing\\\\Digital Signal Processing - Proakis and Manolakis - 4th.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Signal Processing\\\\Information Theory, Probability, and Neural Networks - D. J. C. MacKay.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Signal Processing\\\\M. H. Hayes - Statistical Digital Signal Processing and Modeling (Wiley, 1996).pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Signal Processing\\\\Manolakis D G , Et Al(2005) Statistical And Adaptive Signal Processing Spectral Estimation, Signal Modeling, Adaptive Filtering, And Array Processing(806S).pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Signal Processing\\\\m_hayes_statistical_digital_signal_proc_part_1.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Signal Processing\\\\Nonlinear Programming - Theory And Algorithms 3Rd Ed - M Bazaraa, Et Al , (Wiley, 2006) Ww.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Signal Processing\\\\S. M. Kay - Fundamentals of Statistical Signal Processing Estimation Theory - Problem Solutions (Prentice-Hall).pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Signal Processing\\\\Signals and Systems [Alan V.Oppenheim, Alan S.Willsky, Hamid Nawad, with S.Hamid (Pearson Education, 1998)].pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Signal Processing\\\\Statistical and Adaptive Signal Processing.. Spectral Estimation, Signal Modeling, Adaptive Filtering, and Array Processing(2005).pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Signal Processing\\\\[DSP - audio] - Digital Audio Signal Processing - Zolzer.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Signal Processing\\\\__Adaptive-signal-processing_widrow.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Sociology\\\\A Sociology of Globalization - Saskia Sassen.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Sociology\\\\Anthony Giddens - Politics, Sociology And Social Theory Stanford 1995.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Sociology\\\\Gladwell, Malcolm Little Brown, The Tipping Point - How Little Things Can Make A Big Difference.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Sociology\\\\Max Weber-The Religion of India_ The Sociology of Hinduism and Buddhism (2000).pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Sociology\\\\Sassen, Saskia - A Sociology of Globalization [2007].pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Startup\\\\Creativity - Maximize Your Brainpower - 1000 New Ways To Boost Your Mental Fitness.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Startup\\\\Creativity - The Discipline of Innovation. By Drucker, Peter.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Startup\\\\Creativity - The Six Values Medals The Essential Tool For Success In The 21St Century - Edward De Bono.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Startup\\\\Harvard Business Review Peter Drucker - The Discipline of Innovation.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Startup\\\\Peter Drucker - Creativity - The Discipline of Innovation.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Story Telling\\\\Writing - Character Development And Storytelling For Games.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\SYSTEM ENGINEERING\\\\Graphic Design Thinking.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\SYSTEM ENGINEERING\\\\Norman, Donald - The Design Of Everyday Things.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\SYSTEM ENGINEERING\\\\The Design of Everyday Things - Donald A. Norman.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Time Management\\\\Accelerated Learning (Stephen Covey).pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Çeşitli\\\\Anatomi Konu Kitabı ( PDFDrive.com ).pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Çeşitli\\\\Erol Göka - Türk Grup Davranışı.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Çeşitli\\\\Halil İnalcık - Doğu Batı.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Çeşitli\\\\Halil İnalcık - Osmanlıda Devlet Hukuk Adalet.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Çeşitli\\\\İlber Ortaylı - Cumhuriyetin İlk Yüzyılı 1923-2023.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\İş-Ge\\\\Crucial Conversations.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\İş-Ge\\\\Executive Book Summary - Peter Drucker - Innovation And Entrepreneurship (Powertalk, Book Summary).pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\İş-Ge\\\\Handbook Of Innovation.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\İş-Ge\\\\Psychology - Oxford Handbook of Innovation.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\İş-Ge\\\\Six Sigma Trends Six Sigma Leadership And Innovation Using Triz.pdf',\n",
       " \"E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\İş-Ge\\\\The Art Of Innovation - Lessons In Creativity From Ideo, America's Leading Design Firm.pdf\",\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\İş-Ge\\\\__Browne,Keeley - Asking The Right Questions, A Guide To Critical Thinking, 8Th Ed.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\İş-Ge\\\\__Peter Drucker - Creativity - The Discipline of Innovation.pdf',\n",
       " 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\İş-Ge\\\\__Peter Drucker - Innovation And Entrepreneurship (Powertalk, Resumido).pdf']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find missing docs after document chunks extraction\n",
    "directory = \"D:\\\\Bilgi\"\n",
    "file_dict = get_docs(directory)\n",
    "\n",
    "missing_docs = []\n",
    "\n",
    "\n",
    "counter = 0\n",
    "for file, info in file_dict.items():\n",
    "    print(counter, end=\"\\r\")\n",
    "    counter += 1\n",
    "\n",
    "    filepath = file_dict[file][0][0]\n",
    "    doc_found = False\n",
    "    for item in list_items_info:\n",
    "        doc_name_in_list = item[2]\n",
    "        if filepath == doc_name_in_list:\n",
    "            doc_found = True\n",
    "            break\n",
    "        #print(filepath , \" - \", doc_name_in_list)\n",
    "    if not doc_found:\n",
    "        missing_docs.append(filepath)\n",
    "\n",
    "print(f\"Number of missing docs: {len(missing_docs)}\")\n",
    "\n",
    "\n",
    "missing_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error flag: False, warning flag: False\n",
      "Text: [Document(metadata={'producer': \"Relais Int'l and AIS ImagePDF 1.06\", 'creator': 'PyPDF', 'creationdate': '2003-03-06T06:57:40-05:00', 'moddate': '2007-03-18T17:52:25+01:00', 'source': 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Startup\\\\Creativity - The Discipline of Innovation. By Drucker, Peter.pdf', 'total_pages': 7}, page_content='\\n\\x0c\\n\\x0c\\n\\x0c\\n\\x0c\\n\\x0c\\n\\x0c')]\n",
      "Number of chunks: 0\n",
      "Total number of element in chromadb: 0\n",
      "Number of elements: 0\n",
      "Number of found docs: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Full pipeline for a single document -- for testing\n",
    "\n",
    "def create_batches(data, ids, batch_size):\n",
    "    \"\"\"Yield successive batch_size-sized chunks from data.\"\"\"\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        yield data[i:i + batch_size], ids[i:i + batch_size]\n",
    "\n",
    "\n",
    "file_counter = 0\n",
    "\n",
    "client = chromadb.HttpClient(\n",
    "    host=\"localhost\",  # Server's hostname or IP address\n",
    "    port=8000,         # Port number the server is listening on\n",
    "    settings=Settings(),\n",
    ")\n",
    "collection = client.get_or_create_collection(name=\"my-rag-db\") \n",
    "\n",
    "embedding_function = OllamaEmbeddingFunction(\n",
    "    model_name=\"nomic-embed-text\",\n",
    "    url=\"http://localhost:11434/api/embeddings\",\n",
    ")\n",
    "\n",
    "#chroma run --host localhost --port 8000 --path D:/my_chroma_db_with_langchain2\n",
    "\n",
    "file_path = \"D:\\\\Bilgi\\\\Kitaplar\\\\Startup\\\\Creativity - The Discipline of Innovation. By Drucker, Peter.pdf\"\n",
    "\n",
    "error_flag = False\n",
    "warning_flag = False\n",
    "try:\n",
    "    loader = PyPDFLoader(file_path, mode=\"single\")\n",
    "    doc = loader.load()      \n",
    "except Warning as w:\n",
    "    warning_flag = True\n",
    "    #warning_logger.warning(f\"{file_counter} -- {file_path}: {w}\")\n",
    "except Exception as e:\n",
    "    # Capture the exception and traceback\n",
    "    error_flag = True      \n",
    "    #error_logger.error(f\"{file_counter} -- {file_path}: {e}\", exc_info=True)\n",
    "\n",
    "file_counter += 1  \n",
    "print(f\"Error flag: {error_flag}, warning flag: {warning_flag}\")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "                    chunk_size=512, chunk_overlap=128, add_start_index=True\n",
    "                )\n",
    "\n",
    "print(f\"Text: {doc}\")\n",
    "chunks = text_splitter.split_documents(doc)\n",
    "total_chunks = len(chunks)\n",
    "print(f\"Number of chunks: {total_chunks}\")\n",
    "\n",
    "# Generate unique IDs for each chunk\n",
    "\n",
    "# Generate unique IDs for each chunk\n",
    "chunk_ids = [f\"doc_{file_counter}_chunk_{i}\" for i in range(len(chunks))]\n",
    "\n",
    "\n",
    "batch_size = 128  # Adjust based on your system's capacity\n",
    "total_chunks = len(chunks)\n",
    "\n",
    "\n",
    "#Add chunks data in batches for speed consideration. Operation is same as one chunk at a time in chromadb.\n",
    "#with tqdm(total=total_chunks, desc=f\"{str(file_counter)} / {str(1)} - Adding chunks of {file_path}\", position=1, leave=True, unit=\"chunks\") as pbar:        \n",
    "for batch, batch_ids in create_batches(chunks, chunk_ids, batch_size):\n",
    "    print(\"ilker\")\n",
    "    # Precompute embeddings for the current batch\n",
    "    batch_documents = [chunk.page_content.encode('utf-8', errors='replace').decode('utf-8') for chunk in batch]\n",
    "    batch_metadata = [chunk.metadata for chunk in batch]\n",
    "    batch_embeddings = embedding_function(batch_documents)\n",
    "\n",
    "    #Add the batch to the collection\n",
    "    collection.upsert(\n",
    "        documents=batch_documents,\n",
    "        metadatas=batch_metadata,\n",
    "        ids=batch_ids,\n",
    "        embeddings=batch_embeddings\n",
    "        )\n",
    "    \n",
    "        # Update the progress bar\n",
    "        #pbar.update(len(batch))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#---------------------------------------------\n",
    "\n",
    "import chromadb\n",
    "\n",
    "# Initialize the Chroma client (PersistentClient for persistent storage)\n",
    "client = chromadb.PersistentClient(path=\"D:\\Bilgi\\__Databases\\Bilgi_my_chroma_db_with_langchain\")\n",
    "\n",
    "# Access your collection by name\n",
    "collection = client.get_collection(\"my-rag-db\")\n",
    "\n",
    "total_items = collection.count()\n",
    "print(f\"Total number of element in chromadb: {total_items}\")\n",
    "\n",
    "batch_size = 100000\n",
    "\n",
    "list_items_info = []\n",
    "counter = 0\n",
    "for offset in range(0, total_items, batch_size):\n",
    "    # Retrieve a batch of data\n",
    "\n",
    "    print(f\"Counter: {counter} / {total_items}  \", end=\"\\r\")\n",
    "\n",
    "    batch = collection.get(\n",
    "        include=[\"documents\", \"metadatas\"],\n",
    "        limit=batch_size,\n",
    "        offset=offset\n",
    "    )\n",
    "\n",
    "    # Process each item in the batch\n",
    "    for doc, meta, id in zip(batch[\"documents\"], batch[\"metadatas\"], batch[\"ids\"]):\n",
    "        # Replace the following line with your processing logic\n",
    "        #print(f\"Document: {doc}\\nMetadata: {meta}\\nIds: {id}\\n\")\n",
    "\n",
    "        path = meta.get(\"source\", \"Unknown\")\n",
    "        doc_name = path.split(\"\\\\\")[-1]\n",
    "        page = meta.get(\"page\", \"Unknown\")\n",
    "        total_pages = meta.get(\"total_pages\", \"Unknown\")\n",
    "        chunk_length = len(doc)\n",
    "\n",
    "        list_items_info.append([id, chunk_length, path, doc_name, page, total_pages, doc])\n",
    "\n",
    "        counter += 1\n",
    "    \n",
    "\n",
    "print(f\"Number of elements: {len(list_items_info)}\")\n",
    "\n",
    "#print(list_items_info)\n",
    "\n",
    "#---------------------------------------------------------------\n",
    "\n",
    "directory = \"D:\\\\Bilgi\"\n",
    "file_dict = get_docs(directory)\n",
    "\n",
    "found_docs = []\n",
    "\n",
    "\n",
    "counter = 0\n",
    "for file, info in file_dict.items():\n",
    "    filepath = file_dict[file][0][0]\n",
    "    doc_found = False\n",
    "    for item in list_items_info:\n",
    "        doc_name_in_list = item[2]\n",
    "        if filepath == doc_name_in_list:\n",
    "            doc_found = True\n",
    "            break\n",
    "        #print(filepath , \" - \", doc_name_in_list)\n",
    "    if doc_found:\n",
    "        counter += 1\n",
    "        print(counter, end=\"\\r\")\n",
    "        found_docs.append(filepath)\n",
    "\n",
    "print(f\"Number of found docs: {len(found_docs)}\")\n",
    "\n",
    "\n",
    "found_docs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for query: '\n",
      "başlamışlardı ki, tepeden inip de düzlüğe çıktıkları vakit uğursuz \n",
      "bir rüzgar ejderin püskürttüğü alevlerden artakalan yoğun duma­\n",
      "nı onların bulu nduğu tarafa sürükledi ve atların bile aklını ba­\n",
      "şından alacak kadar berbat bir kokuyla çevrelendiler. Sonra, sisin \n",
      "içinde ne yöne gittiklerini göremezken buna bir de ejder nefesinin \n",
      "o iğrenç kokusunun yarattığı panik eklenin ce, atları kont rol altın­\n",
      "da tutmak imkansız hale geldi ve hayvanlar güzergah değiştirip\n",
      "'\n",
      "Document: başlamışlardı ki, tepeden inip de düzlüğe çıktıkları vakit uğursuz \n",
      "bir rüzgar ejderin püskürttüğü alevlerden artakalan yoğun duma­\n",
      "nı onların bulu nduğu tarafa sürükledi ve atların bile aklını ba­\n",
      "şından alacak kadar berbat bir kokuyla çevrelendiler. Sonra, sisin \n",
      "içinde ne yöne gittiklerini göremezken buna bir de ejder nefesinin \n",
      "o iğrenç kokusunun yarattığı panik eklenin ce, atları kont rol altın­\n",
      "da tutmak imkansız hale geldi ve hayvanlar güzergah değiştirip\n",
      "Metadata: {'creationdate': '2015-01-28T21:07:37+02:00', 'creator': 'Adobe Acrobat 11.0', 'moddate': '2015-01-28T21:43:57+02:00', 'producer': 'Adobe Acrobat Pro 11.0.0 Paper Capture Plug-in with ClearScan', 'source': 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Çeşitli\\\\J. R. R. Tolkien - Bitmemiş Öyküler.pdf', 'start_index': 412318, 'title': '', 'total_pages': 756}\n",
      "ID: doc_1792_chunk_1051\n",
      "Similarity Score (Distance): 0.0\n",
      "\n",
      "----------------------------------------------------------\n",
      "Results for query: '\n",
      "başlamışlardı ki, tepeden inip de düzlüğe çıktıkları vakit uğursuz \n",
      "bir rüzgar ejderin püskürttüğü alevlerden artakalan yoğun duma­\n",
      "'\n",
      "Document: başlamışlardı ki, tepeden inip de düzlüğe çıktıkları vakit uğursuz \n",
      "bir rüzgar ejderin püskürttüğü alevlerden artakalan yoğun duma­\n",
      "nı onların bulu nduğu tarafa sürükledi ve atların bile aklını ba­\n",
      "şından alacak kadar berbat bir kokuyla çevrelendiler. Sonra, sisin \n",
      "içinde ne yöne gittiklerini göremezken buna bir de ejder nefesinin \n",
      "o iğrenç kokusunun yarattığı panik eklenin ce, atları kont rol altın­\n",
      "da tutmak imkansız hale geldi ve hayvanlar güzergah değiştirip\n",
      "Metadata: {'creationdate': '2015-01-28T21:07:37+02:00', 'creator': 'Adobe Acrobat 11.0', 'moddate': '2015-01-28T21:43:57+02:00', 'producer': 'Adobe Acrobat Pro 11.0.0 Paper Capture Plug-in with ClearScan', 'source': 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Çeşitli\\\\J. R. R. Tolkien - Bitmemiş Öyküler.pdf', 'start_index': 412318, 'title': '', 'total_pages': 756}\n",
      "ID: doc_1792_chunk_1051\n",
      "Similarity Score (Distance): 0.2292858511209488\n",
      "\n",
      "----------------------------------------------------------\n",
      "Results for query: 'Emevi dönemi ne zaman başlar?'\n",
      "Document: raber hiçbir zaman, ne var olan gerçekleri ne de ele geçirmek istediği ege­\n",
      "menlik konumunu unuttu . İnsan haklar ını Eski Rejim'e karşı kullanmak için, \n",
      "bunlann doğal ve zaman aşımına uğramaz olduklarını ilan ediyordu. Peki \n",
      "bunlar , toplumdan önce gelen, gerçekten de herkese tanınan, egemenliğin \n",
      "bile dokunamayacağı haklar mıydı? Bu konuda, zaman zaman birbiriyle \n",
      "çatışan görüşler ortaya atıldı ve tartışma hiçbir zaman bir sonuca ulaşmadı.\n",
      "Metadata: {'creationdate': '2016-01-27T05:25:15+02:00', 'creator': 'Adobe Acrobat 11.0', 'moddate': '2016-01-27T05:26:57+02:00', 'producer': 'Adobe Acrobat Pro 11.0.0 Paper Capture Plug-in with ClearScan', 'source': 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Çeşitli\\\\Georges Lefebvre Fransız Devrimi.pdf', 'start_index': 388988, 'title': '', 'total_pages': 665}\n",
      "ID: doc_1782_chunk_997\n",
      "Similarity Score (Distance): 0.5146365165710449\n",
      "\n",
      "----------------------------------------------------------\n",
      "Result \n",
      "\n",
      "Chunk id: doc_1782_chunk_997, metadata: E:\\__ilker\\Bilgi\\Kitaplar\\Çeşitli\\Georges Lefebvre Fransız Devrimi.pdf \n",
      "Content: raber hiçbir zaman, ne var olan gerçekleri ne de ele geçirmek istediği ege­\n",
      "menlik konumunu unuttu . İnsan haklar ını Eski Rejim'e karşı kullanmak için, \n",
      "bunlann doğal ve zaman aşımına uğramaz olduklarını ilan ediyordu. Peki \n",
      "bunlar , toplumdan önce gelen, gerçekten de herkese tanınan, egemenliğin \n",
      "bile dokunamayacağı haklar mıydı? Bu konuda, zaman zaman birbiriyle \n",
      "çatışan görüşler ortaya atıldı ve tartışma hiçbir zaman bir sonuca ulaşmadı.\n",
      "[Document(id='doc_1782_chunk_997', metadata={'creationdate': '2016-01-27T05:25:15+02:00', 'creator': 'Adobe Acrobat 11.0', 'moddate': '2016-01-27T05:26:57+02:00', 'producer': 'Adobe Acrobat Pro 11.0.0 Paper Capture Plug-in with ClearScan', 'source': 'E:\\\\__ilker\\\\Bilgi\\\\Kitaplar\\\\Çeşitli\\\\Georges Lefebvre Fransız Devrimi.pdf', 'start_index': 388988, 'title': '', 'total_pages': 665}, page_content=\"raber hiçbir zaman, ne var olan gerçekleri ne de ele geçirmek istediği ege\\xad\\nmenlik konumunu unuttu . İnsan haklar ını Eski Rejim'e karşı kullanmak için, \\nbunlann doğal ve zaman aşımına uğramaz olduklarını ilan ediyordu. Peki \\nbunlar , toplumdan önce gelen, gerçekten de herkese tanınan, egemenliğin \\nbile dokunamayacağı haklar mıydı? Bu konuda, zaman zaman birbiriyle \\nçatışan görüşler ortaya atıldı ve tartışma hiçbir zaman bir sonuca ulaşmadı.\")]\n",
      "----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Only find similar document chunks according to queries -- for testing\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from chromadb.utils.embedding_functions import OllamaEmbeddingFunction\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainFilter\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from typing import List\n",
    "import logging\n",
    "\n",
    "\n",
    "# Initialize the Chroma client (PersistentClient for persistent storage)\n",
    "embedding = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "\n",
    "# embedding_function = OllamaEmbeddingFunction(\n",
    "#     model_name=\"nomic-embed-text\",\n",
    "#     url=\"http://localhost:11434/api/embeddings\",\n",
    "# )\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name = \"my-rag-db\",\n",
    "    embedding_function=embedding,\n",
    "    persist_directory=\"D:\\\\Bilgi\\\\__Databases\\\\Bilgi_my_chroma_db_with_langchain\"\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define your queries\n",
    "queries = [\n",
    "\"\"\"\n",
    "başlamışlardı ki, tepeden inip de düzlüğe çıktıkları vakit uğursuz \n",
    "bir rüzgar ejderin püskürttüğü alevlerden artakalan yoğun duma­\n",
    "nı onların bulu nduğu tarafa sürükledi ve atların bile aklını ba­\n",
    "şından alacak kadar berbat bir kokuyla çevrelendiler. Sonra, sisin \n",
    "içinde ne yöne gittiklerini göremezken buna bir de ejder nefesinin \n",
    "o iğrenç kokusunun yarattığı panik eklenin ce, atları kont rol altın­\n",
    "da tutmak imkansız hale geldi ve hayvanlar güzergah değiştirip\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "başlamışlardı ki, tepeden inip de düzlüğe çıktıkları vakit uğursuz \n",
    "bir rüzgar ejderin püskürttüğü alevlerden artakalan yoğun duma­\n",
    "\"\"\",\n",
    "\"Emevi dönemi ne zaman başlar?\"   \n",
    "]\n",
    "\n",
    " \n",
    "# Iterate over each query and perform similarity search with scores\n",
    "for query in queries:\n",
    "    results = await vector_store.asimilarity_search_with_score(query, k=1)  # Adjust 'k' as needed\n",
    "\n",
    "    # Process and display results\n",
    "    print(f\"Results for query: '{query}'\")\n",
    "    for doc, score in results:\n",
    "        print(f\"Document: {doc.page_content}\")  # Display first 100 characters\n",
    "        print(f\"Metadata: {doc.metadata}\")  # Display first 100 characters\n",
    "        print(f\"ID: {doc.id}\")  # Display first 100 characters\n",
    "        print(f\"Similarity Score (Distance): {score}\\n\")\n",
    "        print(\"----------------------------------------------------------\")\n",
    "\n",
    "#---------------------------------------------------------------\n",
    "#Create a retriever from vectorstore\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"mmr\", search_kwargs={ \"k\": 1, \"lambda_mult\": 0.7,  \"score_threshold\": 0.8, \"fetch_k\": 10}\n",
    ")\n",
    "found_chunks = retriever.invoke(queries[2])\n",
    "\n",
    "for i in range(len(found_chunks)):\n",
    "    print(\"Result \\n\")\n",
    "    print(f\"Chunk id: {found_chunks[i].id}, metadata: {found_chunks[i].metadata['source']} \")\n",
    "    print(f\"Content: {found_chunks[i].page_content}\")\n",
    "print(found_chunks)\n",
    "\n",
    "print(\"----------------------------------------------------------\")\n",
    "\n",
    "#---------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore created...\n",
      "bm25_data_docs_and_metadata.json read...\n",
      "bm25_retriever ready...\n",
      "data is deleted from RAM...\n"
     ]
    }
   ],
   "source": [
    "#Full RAG app with hybrid search 1/2 - preparation of retrievers \n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from chromadb.utils.embedding_functions import OllamaEmbeddingFunction\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainFilter\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from rank_bm25 import BM25Okapi\n",
    "from langchain.schema import Document\n",
    "from langchain_core.runnables import Runnable, RunnableMap, RunnablePassthrough\n",
    "from langchain_community.document_transformers import LongContextReorder\n",
    "from pydantic import Field\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from typing import List, Dict\n",
    "import logging\n",
    "import json\n",
    "import msgspec\n",
    "from langchain.schema import Document\n",
    "from rank_bm25 import BM25Okapi\n",
    "from typing import List, Dict, Optional\n",
    "import gc\n",
    "\n",
    "\n",
    "\n",
    "class Data(msgspec.Struct):\n",
    "    documents: list[str]\n",
    "    metadatas: list[dict]\n",
    "\n",
    "\n",
    "#Functions for Post-processing to create list of reference documents the LLM used from the all reference documents (text chunks + metadata)\n",
    "def keyword_matching(llm_output, documents):\n",
    "    matched_docs = []\n",
    "    for doc in documents:\n",
    "        doc_keywords = extract_keywords(doc)\n",
    "        if any(keyword in llm_output for keyword in doc_keywords):\n",
    "            matched_docs.append(doc)\n",
    "    return matched_docs\n",
    "\n",
    "def extract_keywords(document):\n",
    "    # Implement your keyword extraction logic here\n",
    "    # This could be as simple as splitting the document into words\n",
    "    # or using more advanced techniques like TF-IDF or RAKE\n",
    "    return document.split()\n",
    "\n",
    "def similarity_assessment(llm_output, documents, threshold=0.5):\n",
    "    # Ensure documents is a list of strings\n",
    "    documents = list(documents)  # Convert generator to list if necessary\n",
    "    documents = [str(doc) for doc in documents]  # Ensure each document is a string\n",
    "\n",
    "    # Combine LLM output and documents into a single corpus\n",
    "    corpus = [llm_output] + documents\n",
    "\n",
    "    # Compute TF-IDF vectors\n",
    "    vectorizer = TfidfVectorizer().fit_transform(corpus)\n",
    "    vectors = vectorizer.toarray()\n",
    "\n",
    "    # Extract LLM output vector and document vectors\n",
    "    llm_vector = vectors[0]\n",
    "    doc_vectors = vectors[1:]\n",
    "\n",
    "    # Compute cosine similarity between LLM output and each document\n",
    "    similarities = cosine_similarity([llm_vector], doc_vectors).flatten()\n",
    "\n",
    "    # Filter documents based on similarity threshold\n",
    "    matched_docs = [doc for doc, sim in zip(documents, similarities) if sim >= threshold]\n",
    "\n",
    "    return matched_docs\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------\n",
    "#Custom BM25Retriever in order to utilize if all keywords are inside a text chunk, give higher score to that chunk in ranking with scores\n",
    "class CustomBM25Retriever(BaseRetriever):\n",
    "    k1: float = Field(default=1.2)\n",
    "    b: float = Field(default=0.75)\n",
    "    phrase_boost: float = Field(default=1.5)\n",
    "    k: int = Field(default=10)  # Number of top documents to retrieve\n",
    "    documents: List[Document] = Field(default_factory=list)\n",
    "    tokenized_docs: List[List[str]] = Field(default_factory=list)\n",
    "    bm25: Optional[BM25Okapi] = None\n",
    "\n",
    "    def __init__(self, documents: List[Document], k: int = 10, k1: float = 1.2, b: float = 0.75, phrase_boost: float = 1.5):\n",
    "        super().__init__(documents=documents, k=k, k1=k1, b=b, phrase_boost=phrase_boost)\n",
    "        self.k = k\n",
    "        self.tokenized_docs = [self.tokenize(doc) for doc in self.documents]\n",
    "        self.bm25 = BM25Okapi(self.tokenized_docs, k1=self.k1, b=self.b)\n",
    "\n",
    "    @classmethod\n",
    "    def from_texts(cls, texts: List[str], metadatas: Optional[List[Dict]] = None, k: int = 10, bm25_params: Optional[Dict] = None):\n",
    "        \"\"\" Factory method to initialize from raw texts and metadata (similar to LangChain's BM25Retriever) \"\"\"\n",
    "        bm25_params = bm25_params or {\"k1\": 1.2, \"b\": 0.75}\n",
    "        documents = [Document(page_content=text, metadata=meta) for text, meta in zip(texts, metadatas or [{}] * len(texts))]\n",
    "        return cls(documents, k=k , **bm25_params)\n",
    "\n",
    "    def tokenize(self, doc: Document):\n",
    "        \"\"\" Tokenizes both content and metadata for retrieval \"\"\"\n",
    "        metadata_str = \" \".join(f\"{key}: {value}\" for key, value in doc.metadata.items())\n",
    "        full_text = f\"{doc.page_content} {metadata_str}\"\n",
    "        return full_text.split()\n",
    "\n",
    "    def _get_relevant_documents(self, query: str) -> List[Document]:\n",
    "        \"\"\" Retrieve and rank documents using BM25 with metadata and phrase boosting \"\"\"\n",
    "        query_tokens = query.split()\n",
    "        scores = self.bm25.get_scores(query_tokens)\n",
    "\n",
    "        # Boost score if query appears as a phrase\n",
    "        boosted_scores = []\n",
    "        for i, doc in enumerate(self.documents):\n",
    "            full_text = f\"{doc.page_content} \" + \" \".join(f\"{key}: {value}\" for key, value in doc.metadata.items())\n",
    "            phrase_bonus = self.phrase_boost if query in full_text else 1.0\n",
    "            boosted_scores.append(scores[i] * phrase_bonus)\n",
    "\n",
    "        # Rank documents by boosted BM25 score\n",
    "        ranked_docs = sorted(zip(self.documents, boosted_scores), key=lambda x: x[1], reverse=True)\n",
    "        return [doc[0] for doc in ranked_docs[:self.k]]  # Return only top_k documents\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------\n",
    "# Function to process retrieved documents\n",
    "class RetrieveAndFormat(Runnable):\n",
    "    def __init__(self, retriever):\n",
    "        self.retriever = retriever\n",
    "\n",
    "    def invoke(self, inputs: Dict[str, str], config=None) -> Dict[str, str]:\n",
    "        question = inputs['question']\n",
    "        retrieved_docs: List[Document] = self.retriever.invoke(question)\n",
    "        if not retrieved_docs:\n",
    "            return {\"context\": \"No info\", \"metadata\": \"No info\", \"question\": question, \"context_with_metadata\": \"No info\"}\n",
    "        \n",
    "        reordering = LongContextReorder()\n",
    "        reordered_docs = reordering.transform_documents(retrieved_docs)\n",
    "\n",
    "        context = \"\\n\\n\".join([doc.page_content for doc in reordered_docs])\n",
    "\n",
    "        # Initialize an empty set to track seen sources\n",
    "        seen_sources = set()\n",
    "\n",
    "        # Initialize a list to store unique metadata entries\n",
    "        unique_metadata = []\n",
    "\n",
    "        # Iterate over the retrieved documents\n",
    "        counter=1\n",
    "        for doc in reordered_docs:\n",
    "            # Extract the 'source' metadata, defaulting to 'Unknown' if not present\n",
    "            source = doc.metadata.get('source', 'Unknown')\n",
    "            # If this source has not been encountered before, add it to the set and list\n",
    "            if source not in seen_sources:\n",
    "                seen_sources.add(source)\n",
    "                unique_metadata.append(f\"Source-{str(counter)}: {source}\")\n",
    "                counter += 1\n",
    "\n",
    "        # Join the unique metadata entries into a single string with double newlines\n",
    "        metadata = \"\\n\\n\".join(unique_metadata)\n",
    "\n",
    "        context_with_metadata = \"\\n\\n\".join([\"\\n\".join([doc.page_content, doc.metadata.get('source', 'Unknown')]) for doc in reordered_docs])\n",
    "\n",
    "        return {\"context\": context, \"metadata\": metadata, \"question\": question, \"context_with_metadata\": context_with_metadata}\n",
    "    \n",
    "\n",
    "#--------------------------------------------------------------------------------------------------\n",
    "# Initialize the Chroma client (PersistentClient for persistent storage)\n",
    "#embedding = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "embedding = OllamaEmbeddings(model=\"bge-m3\")\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name = \"my-rag-db\",\n",
    "    embedding_function=embedding,\n",
    "    persist_directory=\"D:\\\\Bilgi\\\\__Databases\\\\Bilgi_my_chroma_db_with_langchain\"\n",
    "    )\n",
    "\n",
    "print(\"Vectorstore created...\")\n",
    "\n",
    "#---------------------------------------------------------------\n",
    "\n",
    "# #Create bm25 retriever and save it for one time\n",
    "# stored_data = vector_store.get()\n",
    "# doc_list =  stored_data.get('documents', [])\n",
    "# metadata_list = stored_data.get('metadatas', [])\n",
    "# data_to_save = {\n",
    "#     'documents': doc_list,\n",
    "#     'metadatas': metadata_list\n",
    "# }\n",
    "\n",
    "# print(\"Data to save created for BM25 retriever...\")\n",
    "\n",
    "# with open('D:\\\\Bilgi\\\\__Databases\\\\bm25_data_docs_and_metadata.json', 'w', encoding='utf-8') as file:\n",
    "#     json.dump(data_to_save, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "# print(\"Data to saved for BM25 retriever...\")\n",
    "\n",
    "#------------------------\n",
    "#Read the document chunks and metadata as a file and put them into the BM25REtriever -- heavy RAM load\n",
    "with open('D:\\\\Bilgi\\\\__Databases\\\\bm25_data_docs_and_metadata.json', 'rb') as file:\n",
    "    data = msgspec.json.decode(file.read(), type=Data)\n",
    "\n",
    "print(\"bm25_data_docs_and_metadata.json read...\")\n",
    "\n",
    "# Initialize Custom BM25 Retriever instead of default BM25Retriever\n",
    "#bm25_retriever = BM25Retriever.from_texts(data.documents, metadatas=data.metadatas, bm25_params={\"k1\": 0.8, \"b\": 0.5})\n",
    "bm25_retriever = CustomBM25Retriever.from_texts(data.documents, data.metadatas, k=10, bm25_params={\"k1\": 0.8, \"b\": 0.5, \"phrase_boost\": 1.0})\n",
    "\n",
    "print(\"bm25_retriever ready...\") \n",
    "\n",
    "del data\n",
    "gc.collect()\n",
    "print(\"data is deleted from RAM...\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ensemble_retriever created\n",
      "RAG chain ready...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.multi_query:Generated queries: ['\"What does \\'stock\\' mean in corporate finance?\"', '\"How is \\'stock\\' defined in corporate finance?\"', '\"What\\'s the definition of \\'stock\\' in corporate finance?\"']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----------------------\n",
      "----------------------\n",
      "Answer: \n",
      "In corporate finance, stocks refer to equity securities that represent ownership in a corporation. Here are some key aspects of stocks:\n",
      "\n",
      "1. **Ownership**: Stockholders (also known as shareholders) own a fraction of the company proportional to their holdings. They have voting rights and can participate in major corporate decisions.\n",
      "\n",
      "2. **Dividends**: Corporations may distribute a portion of their profits as dividends to stockholders, typically on a per-share basis. However, dividends are not guaranteed and depend on the company's earnings and board of directors' decision.\n",
      "\n",
      "3. **Capital Appreciation**: Stock prices can fluctuate based on the company's performance, market conditions, and other factors. When a stock is bought at a lower price and sold at a higher price, the owner profits from capital appreciation.\n",
      "\n",
      "4. **Risk/Reward Trade-off**: Stocks are generally considered riskier than bonds or other debt securities because they do not have a guaranteed return like bonds. However, stocks also offer potentially higher returns due to this higher risk.\n",
      "\n",
      "5. **Types of Stock**: There are two main types of stock:\n",
      "   - **Common Stock**: This is the most common type and represents ownership in the company with voting rights.\n",
      "   - **Preferred Stock**: Preferred stockholders have priority over common stockholders regarding dividend payments and asset distribution in case of liquidation or bankruptcy. However, they usually do not have voting rights.\n",
      "\n",
      "In corporate finance, stocks are a crucial component as they represent one way companies raise capital (through issuing new shares), and they also play a significant role in determining the company's market value and cost of capital.\n",
      "\n",
      "Relevant documents LLM model used:\n",
      "\n",
      "Source-1: D:\\Bilgi\\Kitaplar\\Economy\\Principles of Macroeconomics  -  Mankiw N. Gregory -  ( South-Western, Cengage Learning - 5nd Ed.2009 - pp.585 ).pdf\n",
      "\n",
      "Source-2: D:\\Bilgi\\Kitaplar\\Investing\\2010.The Financial Times Guide to Investing.Investment Management.pdf\n",
      "\n",
      "Source-3: D:\\Bilgi\\Kitaplar\\Economy\\Case, Karl E  Fair, Ray C  Oster, Sharon E - Principles Of Macroeconomics-Pearson (2017).pdf\n",
      "\n",
      "Source-4: D:\\Bilgi\\Kitaplar\\Investing\\!_The Little Book Of Common Sense Investing - The Only Way To Guarantee Your Fair Share Of Stock Market Returns[index.invest] - 2007.-.Bogle.pdf\n",
      "\n",
      "Source-5: D:\\Bilgi\\Kitaplar\\Business\\Corporate Finance (2014).pdf\n",
      "\n",
      "Source-6: D:\\Bilgi\\Kitaplar\\Business\\Ross, Westerfield, Jaffe Corporate Finance.pdf\n",
      "\n",
      "\n",
      "----------------------\n",
      "----------------------\n",
      "All relevant documents:\n",
      "\n",
      "Source-1: D:\\Bilgi\\Kitaplar\\Economy\\Principles of Macroeconomics  -  Mankiw N. Gregory -  ( South-Western, Cengage Learning - 5nd Ed.2009 - pp.585 ).pdf\n",
      "\n",
      "Source-2: D:\\Bilgi\\Kitaplar\\Investing\\2010.The Financial Times Guide to Investing.Investment Management.pdf\n",
      "\n",
      "Source-3: D:\\Bilgi\\Kitaplar\\Economy\\Case, Karl E  Fair, Ray C  Oster, Sharon E - Principles Of Macroeconomics-Pearson (2017).pdf\n",
      "\n",
      "Source-4: D:\\Bilgi\\Kitaplar\\Economy\\Economics.Today.The.Macro.View,.Roger.LeRoy.Miller,.16ed,.AW,.2012.pdf\n",
      "\n",
      "Source-5: D:\\Bilgi\\Kitaplar\\Investing\\!_The Little Book Of Common Sense Investing - The Only Way To Guarantee Your Fair Share Of Stock Market Returns[index.invest] - 2007.-.Bogle.pdf\n",
      "\n",
      "Source-6: D:\\Bilgi\\Kitaplar\\Accounting\\010711_English_Finance_Management_Accounting_The_agile_manager's_guide_to_understanding_financial_statements.pdf\n",
      "\n",
      "Source-7: D:\\Bilgi\\Kitaplar\\Business\\Ross, Westerfield, Jaffe Corporate Finance.pdf\n",
      "\n",
      "Source-8: D:\\Bilgi\\Kitaplar\\Investing\\9. Aswath Damodaran - Investment Valuation-Wiley (2012).epub\n",
      "\n",
      "Source-9: D:\\Bilgi\\Kitaplar\\Business\\Corporate Finance (2014).pdf\n",
      "\n",
      "Source-10: D:\\Bilgi\\Kitaplar\\__SPINGER BOOKS\\2018_Book_PoliticalSocialWork.pdf\n",
      "\n",
      "\n",
      "----------------------\n",
      "----------------------\n",
      "a firm and is, therefore, a claim to the profits that the firm makes. For example, if \n",
      "Intel sells a total of 1,000,000 shares of stock, then each share represents ownership \n",
      "of 1/1,000,000 of the business.\n",
      " The sale of stock to raise money is called equity finance , whereas the sale of \n",
      "bonds is called debt finance . Although corporations use both equity and debt \n",
      "finance to raise money for new investments, stocks and bonds are very different. \n",
      "stock\n",
      "a claim to partial owner-\n",
      "ship in a firm\n",
      "D:\\Bilgi\\Kitaplar\\Economy\\Principles of Macroeconomics  -  Mankiw N. Gregory -  ( South-Western, Cengage Learning - 5nd Ed.2009 - pp.585 ).pdf\n",
      "\n",
      "Stocks and shares\n",
      "The terms ‘stocks’ and ‘shares’ are used interchangeably and confusingly \n",
      "in the financial press, particularly when referring to the US markets. In the \n",
      "1  Capital structure: the proportion of debt to equity making up the total finance supplied \n",
      "to the company.\n",
      "M01_ARNO3745_02_SE_C01.indd   13 16/10/09   09:41:09\n",
      "\f14  The Financial Times Guide to Investing\n",
      "UK we define shares as equity in companies. Stocks are financial instruments\n",
      "D:\\Bilgi\\Kitaplar\\Investing\\2010.The Financial Times Guide to Investing.Investment Management.pdf\n",
      "\n",
      "of stock  is a financial instrument that gives the holder a share in the firm’s ownership and there-\n",
      "fore the right to share in the firm’s profits. If the firm does well, the value of the stock increases \n",
      "and the stockholder receives a capital gain1 on the initial purchase. In addition, the stock may pay \n",
      "dividends—that is, the firm may return some of its profits directly to its stockholders instead of \n",
      "retaining the profits to buy capital. If the firm does poorly, so does the stockholder. The capital\n",
      "D:\\Bilgi\\Kitaplar\\Economy\\Case, Karl E  Fair, Ray C  Oster, Sharon E - Principles Of Macroeconomics-Pearson (2017).pdf\n",
      "\n",
      "rates and tax revenues.\n",
      "Stock The quantity of something, meas-\n",
      "ured at a given point in time—for exam-\n",
      "ple, an inventory of goods or a bank\n",
      "account. Stocks are deﬁned independently\n",
      "of time, although they are assessed at a\n",
      "point in time.\n",
      "Store of value The ability to hold \n",
      "value over time; a necessary property of\n",
      "money.\n",
      "Strategic dependence A situation in\n",
      "which one firm’s actions with respect to\n",
      "price, quality, advertising, and related\n",
      "changes may be strategically countered\n",
      "D:\\Bilgi\\Kitaplar\\Economy\\Economics.Today.The.Macro.View,.Roger.LeRoy.Miller,.16ed,.AW,.2012.pdf\n",
      "\n",
      "AAA) or in investment-grade corporate bonds (rated\n",
      "BBB or better), and holding more in below-investment-\n",
      "grade bonds (BB or lower), or even some so-called junk\n",
      "bonds, rated below CC or even unrated.\n",
      "Since stocks represent the residual ownership (or equity)\n",
      "of corporations, the word safety is not usually associated\n",
      "with them. Unlike bonds, stocks can’t default. Bonds, on\n",
      "the other hand, represent debt. If the payments of interest\n",
      "that corporations and governments promise to make every\n",
      "D:\\Bilgi\\Kitaplar\\Investing\\!_The Little Book Of Common Sense Investing - The Only Way To Guarantee Your Fair Share Of Stock Market Returns[index.invest] - 2007.-.Bogle.pdf\n",
      "\n",
      "the balances in its asset, liability, and stockholders’ equity ac-\n",
      "counts. It’s governed by the formula Assets = Liabilities + Stock-\n",
      "holders’ Equity.\n",
      "BOND. A long-term, interest-bearing promissory note that\n",
      "companies may use to borrow money for periods of time such\n",
      "as five, ten, or twenty years.\n",
      "BOOK VALUE. An asset’s cost basis minus accumulated depre-\n",
      "ciation.\n",
      "BOOK VALUE OF COMMON STOCK. The theoretical amount per\n",
      "share that each stockholder would receive if a company’s assets\n",
      "D:\\Bilgi\\Kitaplar\\Accounting\\010711_English_Finance_Management_Accounting_The_agile_manager's_guide_to_understanding_financial_statements.pdf\n",
      "\n",
      "percent of stock Aand 30 percent of stock B?\n",
      "c. What is the beta of the portfolio in part (b)?\n",
      "Appendix 10A IS BETA DEAD?\n",
      "The capital-asset-pricing model represents one of the most important advances in financial\n",
      "economics. It is clearly useful for investment purposes, since it shows how the expected re-\n",
      "turn on an asset is related to its beta. In addition, we will show in Chapter 12 that it is use-\n",
      "ful in corporate finance, since the discount rate on a project is a function of the project’s\n",
      "D:\\Bilgi\\Kitaplar\\Business\\Ross, Westerfield, Jaffe Corporate Finance.pdf\n",
      "\n",
      "a. What is the value per share, using the Gordon growth model?\n",
      "\n",
      "b. The stock was trading for $80 per share. What would the growth rate in dividends have to be to justify this price?\n",
      "\n",
      "3. Church & Dwight, a large producer of sodium bicarbonate, reported earnings per share of $1.50 in 1993 and paid dividends per share of $0.42. In 1993, the firm also reported the following:\n",
      "\n",
      "The firm faced a corporate tax rate of 38.5%. (The market value debt-to-equity ratio is 5%. The Treasury bond rate is 7%.)\n",
      "D:\\Bilgi\\Kitaplar\\Investing\\9. Aswath Damodaran - Investment Valuation-Wiley (2012).epub\n",
      "\n",
      "contests to replace the board and management. As we will see, these actions interact in \n",
      "complicated ways. For example, as a manager owns more stock in the firm, his incentives \n",
      "become better aligned, but, in addition to the increase in risk the manager must bear, the \n",
      "manager also becomes harder to fire because the block of stock gives him significant voting \n",
      "rights.\n",
      "Let’s now take a closer look at the components of the corporate governance system.\n",
      "CONCEPT CHECK  1. What is corporate governance?\n",
      "D:\\Bilgi\\Kitaplar\\Business\\Corporate Finance (2014).pdf\n",
      "\n",
      "that someone who invested in them instead of in the stock market needs a course in finance?\n",
      "A complete answer to these questions lies at the heart of modern finance, and Chapter 10\n",
      "is devoted entirely to this. However, part of the answer can be found in the variability of the\n",
      "R /H110050.1370 /H110010.3580 /H110010.4514 /H110020.0888\n",
      "4 /H110050.2144\n",
      "Mean /H11005R /H11005/H20896R1 /H11001. . . /H11001RT/H20897\n",
      "T\n",
      "232 Part III Risk\n",
      "D:\\Bilgi\\Kitaplar\\Business\\Ross, Westerfield, Jaffe Corporate Finance.pdf\n",
      "\n",
      "• What are three implications of the efficient-market hypothesis for corporate finance?\n",
      "13.6 SUMMARY AND CONCLUSIONS\n",
      "1. An efficient financial market processes the information available to investors and\n",
      "incorporates it into the prices of securities. Market efficiency has two general implications.\n",
      "First, in any given time period, a stock’s abnormal return depends on information or news\n",
      "received by the market in that period. Second, an investor who uses the same information as\n",
      "D:\\Bilgi\\Kitaplar\\Business\\Ross, Westerfield, Jaffe Corporate Finance.pdf\n",
      "\n",
      "the National Conference of State Legislatures web page:\n",
      "http://www.ncsl.org/research/elections-and-campaigns/disclosure-and-\n",
      "reporting-requirements.aspx\n",
      "What are the requirements for a campaign treasurer within your state? \n",
      "What is the name of the office in your state that oversees campaign finance? \n",
      "What trainings and services do they offer campaigns in your state?\n",
      "Section 6: Do Not Pass Go: Have Financial Experts on Board\n",
      "\f392\n",
      "D:\\Bilgi\\Kitaplar\\__SPINGER BOOKS\\2018_Book_PoliticalSocialWork.pdf\n",
      "\n",
      "(ESOP) debt.\n",
      "• What is corporate debt? Describe its general features.\n",
      "• Why is it sometimes difficult to tell whether a particular security is debt or equity?\n",
      "14.3 PREFERRED STOCK\n",
      "Preferred stock represents equity of a corporation, but it is different from common stock\n",
      "because it has preference over common stock in the payment of dividends and in the assets\n",
      "of the corporation in the event of bankruptcy. Preferencemeans only that the holder of the\n",
      "D:\\Bilgi\\Kitaplar\\Business\\Ross, Westerfield, Jaffe Corporate Finance.pdf\n",
      "\n",
      "voted to developing methods for evaluating risky opportunities.\n",
      "• What are three basic questions of corporate finance?\n",
      "• Describe capital structure.\n",
      "• How is value created?\n",
      "• List the three reasons why value creation is difficult.\n",
      "1.2 CORPORATE SECURITIES AS CONTINGENT CLAIMS ON\n",
      "TOTAL FIRM VALUE\n",
      "What is the essential difference between debt and equity? The answer can be found by think-\n",
      "ing about what happens to the payoffs to debt and equity when the value of the firm changes.\n",
      "D:\\Bilgi\\Kitaplar\\Business\\Ross, Westerfield, Jaffe Corporate Finance.pdf\n",
      "\n",
      "One of the most significant observations of stock market data is this long-run excess of\n",
      "the stock return over the risk-free return. An investor for this period was rewarded for in-\n",
      "vestment in the stock market with an extra or excess return over what would have been\n",
      "achieved by simply investing in T-bills.\n",
      "Why was there such a reward? Does it mean that it never pays to invest in T-bills and\n",
      "that someone who invested in them instead of in the stock market needs a course in finance?\n",
      "D:\\Bilgi\\Kitaplar\\Business\\Ross, Westerfield, Jaffe Corporate Finance.pdf\n",
      "\n",
      "sales at distressed prices when the seller needs cash immediately. This drop in price and subse-\n",
      "quent rebound of 1.86 percent is evidence of price pressure.\n",
      "The preceding are just two of a large number of studies in the area. Because the mag-\n",
      "nitude of the price-pressure effect varies across the existing research, more work is needed\n",
      "to resolve the conflicting results.\n",
      "• What are three implications of the efficient-market hypothesis for corporate finance?\n",
      "13.6 SUMMARY AND CONCLUSIONS\n",
      "D:\\Bilgi\\Kitaplar\\Business\\Ross, Westerfield, Jaffe Corporate Finance.pdf\n"
     ]
    }
   ],
   "source": [
    "#Full RAG app with hybrid search 2/2 - applying doc search with question\n",
    "\n",
    "question = \"What is stock in corporate finance?\"   \n",
    "\n",
    "\n",
    "model = \"mistral-nemo\"  #\"llama3.2:1b\"\n",
    "llm = ChatOllama(model=model, temperature=0.1, repeat_penalty=1.1, streaming=True)  #, callbacks=[StreamingStdOutCallbackHandler()]\n",
    "\n",
    "\n",
    "QUERY_PROMPT = PromptTemplate(\n",
    "input_variables=[\"question\"],\n",
    "template=\n",
    "\"\"\"You are an AI language model assistant. Your task is taking a natural language query from a user and converting it into \n",
    "three queries for a vectorstore with the same language of the question. By generating multiple perspectives on the user question, \n",
    "your goal is to help the user overcome some of the limitations of the distance-based similarity search. \n",
    "Provide these alternative questions separated by newlines.\n",
    "Original question: {question}\"\"\",\n",
    ")\n",
    "\n",
    "DEFAULT_PROMPT = PromptTemplate(\n",
    "input_variables=[\"question\"],\n",
    "template=\n",
    "\"\"\"You are an assistant tasked with taking a natural language\n",
    "query from a user and converting it into a query for a vectorstore with the same language of the question.\n",
    "In this process, you strip out information that is not relevant for\n",
    "the retrieval task. Here is the user query: {question}\"\"\",\n",
    ")\n",
    "\n",
    "\n",
    "#Alternative parameters for search_type=\"similarity\" or \"mmr\"\n",
    "#search_as = {\"score_threshold\": 0.6, \"k\": 10}  #For search_type=\"similarity\"\n",
    "search_as = { \"k\": 5, \"lambda_mult\": 0.8,  \"score_threshold\": 0.6, \"fetch_k\": 20} #'filter': {'paper_title':'GPT-4 Technical Report'}\n",
    "retriever_contextual = MultiQueryRetriever.from_llm(\n",
    "    #vector_store.as_retriever(search_type=\"similarity_score_threshold\",search_kwargs=search_as), \n",
    "    vector_store.as_retriever(search_type=\"mmr\",search_kwargs=search_as), \n",
    "    llm=llm, \n",
    "    prompt=QUERY_PROMPT   #DEFAULT_PROMPT,\n",
    ")\n",
    "\n",
    "logging.basicConfig()\n",
    "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)\n",
    "\n",
    "#Hybrid retrieval: This is for extracting relevant text chunks and metadata according to the question. They will be sent to LLM for creating answer\n",
    "# initialize the ensemble retriever\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, retriever_contextual], rank_fusion=\"reciprocal\"\n",
    ")\n",
    "\n",
    "\n",
    "print(\"ensemble_retriever created\")\n",
    "\n",
    "# RAG prompt: It contains retrieved text chunks and metadata, also chunks+metadata together\n",
    "template = \"\"\"Answer the question using only most relevant context-with-metadata among the provided ones with the same language of the question.\n",
    "Generate concise and non-repetitive paragraphs. If there is no relevant information from the context or metadata, say only 'No info'.\n",
    "Context:\n",
    "{context}\n",
    "Metadata:\n",
    "{metadata}\n",
    "Context-with-metadata:\n",
    "{context_with_metadata}\n",
    "Question: \n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Create the RunnableSequence\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "print(\"RAG chain ready...\")\n",
    "\n",
    "# Instantiate the custom Runnable with your retriever\n",
    "retrieve_and_format = RetrieveAndFormat(ensemble_retriever)\n",
    "\n",
    "\n",
    "# Retrieve context and metadata - sent the question to the LLM \n",
    "retrieval_output = retrieve_and_format.invoke({\"question\": question})\n",
    "\n",
    "\n",
    "\n",
    "# Generate the answer using the complete chain. Answer is streamed.\n",
    "res = chain.stream(retrieval_output)\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"----------------------\")\n",
    "print(\"----------------------\")\n",
    "\n",
    "#Print answer to the question by LLM\n",
    "chunks = []\n",
    "print(\"Answer: \")\n",
    "for chunk in res:\n",
    "    chunks.append(chunk)\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "\n",
    "\n",
    "#Get the answer of the LLM and look for retrieved chunks firstly. Then, apply similarity search to understand LLM chose which chunks and docs\n",
    "res_string = ''.join(chunks)\n",
    "\n",
    "documents= retrieval_output[\"context_with_metadata\"].split(\"\\n\\n\") #These are doc chunks with metadata (aka. book paths)\n",
    "llm_output = res_string  #LLM answer\n",
    "\n",
    "\n",
    "# # Keyword Matching\n",
    "# matched_docs_keywords = keyword_matching(llm_output, documents)\n",
    "# print(\"Documents matched by keyword:\", len(matched_docs_keywords))\n",
    "\n",
    "# Similarity Assessment\n",
    "matched_docs_similarity = similarity_assessment(llm_output, documents, threshold=0.2) #Find similarities between LLM answer and retrieved text chunks\n",
    "\n",
    "\n",
    "# Initialize an empty set to track seen sources\n",
    "seen_sources = set()\n",
    "\n",
    "# Initialize a list to store unique metadata entries\n",
    "unique_metadata = []\n",
    "\n",
    "# Iterate over the retrieved documents: If multiple chunks are obtained from the same document, only that document will be printed as references\n",
    "counter=1\n",
    "for doc in matched_docs_similarity:\n",
    "    # Extract the 'source' metadata, defaulting to 'Unknown' if not present\n",
    "    source = doc.split(\"\\n\")[-1]\n",
    "    # If this source has not been encountered before, add it to the set and list\n",
    "    if source not in seen_sources:\n",
    "        seen_sources.add(source)\n",
    "        unique_metadata.append(f\"Source-{str(counter)}: {source}\")\n",
    "        counter += 1    \n",
    "\n",
    "unique_metadata = \"\\n\\n\".join(unique_metadata)\n",
    "print(f\"\\n\\nRelevant documents LLM model used:\\n\\n{unique_metadata}\") \n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"----------------------\")\n",
    "print(\"----------------------\")\n",
    "\n",
    "#Print all relevant documents according to the question -- for testing purpose\n",
    "ref_docs =  retrieval_output['metadata']\n",
    "print(f\"All relevant documents:\\n\\n{ref_docs}\")    \n",
    "\n",
    "#Access the metadata and print that\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"----------------------\")\n",
    "print(\"----------------------\")\n",
    "\n",
    "#Print all relevant doc chunks with metadata (aka. book paths) -- for testing purpose\n",
    "print(retrieval_output[\"context_with_metadata\"])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#context =  retrieval_output['context']\n",
    "#print(f\"\\nRelevant context and documents:\\n\\n{context}\")\n",
    "\n",
    "#ref_docs =  retrieval_output['metadata']\n",
    "#print(f\"\\nRelevant context and documents:\\n\\n{list(ref_docs)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
